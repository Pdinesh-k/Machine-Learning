{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch workflow :\n",
        "\n",
        "1) Prepare and Load the Data\n",
        "\n",
        "2) Fitting the model to data\n",
        "\n",
        "3) Making predictions and evaluating the model\n",
        "\n",
        "4) Saving and loading a model\n",
        "\n",
        "5) Putting it all together"
      ],
      "metadata": {
        "id": "lc7nx6EScgis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "Skuw7iCBiJvo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "5QNnA-jGYHfM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#workflow of LinearRegression\n",
        "\n",
        "weight = 1\n",
        "bias = 0.0\n",
        "\n",
        "start = 2\n",
        "end = 101\n",
        "range = 2\n",
        "X = torch.arange(start,end,range).unsqueeze(dim=1)\n",
        "y = weight*X+bias"
      ],
      "metadata": {
        "id": "gK2ad4gUetHA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "JKqmlkAviH4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e652ed-256d-4c8a-91c8-04786e3dbc4f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2],\n",
              "        [  4],\n",
              "        [  6],\n",
              "        [  8],\n",
              "        [ 10],\n",
              "        [ 12],\n",
              "        [ 14],\n",
              "        [ 16],\n",
              "        [ 18],\n",
              "        [ 20],\n",
              "        [ 22],\n",
              "        [ 24],\n",
              "        [ 26],\n",
              "        [ 28],\n",
              "        [ 30],\n",
              "        [ 32],\n",
              "        [ 34],\n",
              "        [ 36],\n",
              "        [ 38],\n",
              "        [ 40],\n",
              "        [ 42],\n",
              "        [ 44],\n",
              "        [ 46],\n",
              "        [ 48],\n",
              "        [ 50],\n",
              "        [ 52],\n",
              "        [ 54],\n",
              "        [ 56],\n",
              "        [ 58],\n",
              "        [ 60],\n",
              "        [ 62],\n",
              "        [ 64],\n",
              "        [ 66],\n",
              "        [ 68],\n",
              "        [ 70],\n",
              "        [ 72],\n",
              "        [ 74],\n",
              "        [ 76],\n",
              "        [ 78],\n",
              "        [ 80],\n",
              "        [ 82],\n",
              "        [ 84],\n",
              "        [ 86],\n",
              "        [ 88],\n",
              "        [ 90],\n",
              "        [ 92],\n",
              "        [ 94],\n",
              "        [ 96],\n",
              "        [ 98],\n",
              "        [100]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muSawC1iv8d5",
        "outputId": "6ac76a80-f9aa-4616-f9d0-c6973f1c16a8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2.],\n",
              "        [  4.],\n",
              "        [  6.],\n",
              "        [  8.],\n",
              "        [ 10.],\n",
              "        [ 12.],\n",
              "        [ 14.],\n",
              "        [ 16.],\n",
              "        [ 18.],\n",
              "        [ 20.],\n",
              "        [ 22.],\n",
              "        [ 24.],\n",
              "        [ 26.],\n",
              "        [ 28.],\n",
              "        [ 30.],\n",
              "        [ 32.],\n",
              "        [ 34.],\n",
              "        [ 36.],\n",
              "        [ 38.],\n",
              "        [ 40.],\n",
              "        [ 42.],\n",
              "        [ 44.],\n",
              "        [ 46.],\n",
              "        [ 48.],\n",
              "        [ 50.],\n",
              "        [ 52.],\n",
              "        [ 54.],\n",
              "        [ 56.],\n",
              "        [ 58.],\n",
              "        [ 60.],\n",
              "        [ 62.],\n",
              "        [ 64.],\n",
              "        [ 66.],\n",
              "        [ 68.],\n",
              "        [ 70.],\n",
              "        [ 72.],\n",
              "        [ 74.],\n",
              "        [ 76.],\n",
              "        [ 78.],\n",
              "        [ 80.],\n",
              "        [ 82.],\n",
              "        [ 84.],\n",
              "        [ 86.],\n",
              "        [ 88.],\n",
              "        [ 90.],\n",
              "        [ 92.],\n",
              "        [ 94.],\n",
              "        [ 96.],\n",
              "        [ 98.],\n",
              "        [100.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.is_tensor(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faxDSRcMwCV9",
        "outputId": "aa9139e9-2899-43c2-9cd1-6db9c0ea935a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "id": "Qfswo7f7yAWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ff2fea-d9a8-4dc3-98f2-7229ac3fcb0f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IvHgD_SVIbG",
        "outputId": "d6b19ee2-72fc-45d0-c8cc-3154bdf8de97"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting the Data into training , testing\n",
        "\n",
        "It is always advisory to divide the dataset into 80% for training , 20% for testing"
      ],
      "metadata": {
        "id": "JYYCZd4CUhTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a train\\test split\n",
        "train_split = int(0.80 * len(X))\n",
        "x_train , y_train = X[:train_split] , y[:train_split]\n",
        "x_test , y_test = X[train_split:] , y[train_split:]"
      ],
      "metadata": {
        "id": "VIM63gcIUlKp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train : {len(x_train)} , x_test : {len(x_test)} , y_train : {len(y_train)} , y_test : {len(y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVKwEeiPW_Gc",
        "outputId": "04401a27-462c-4ff6-ea3d-757e089f09c5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train : 40 , x_test : 10 , y_train : 40 , y_test : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What our model does :\n",
        "\n",
        "* Start with random values (weights & bias)\n",
        "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weights & bias values we used to create the data)\n",
        "\n",
        "Through two main algorithms\n",
        "\n",
        "1) Gradient descent\n",
        "\n",
        "2) Backpropagation"
      ],
      "metadata": {
        "id": "uhmD7lnF2UWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "#Create a Linear Regression model\n",
        "#Almost everything inherits from nn.Module\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(1,requires_grad = True,dtype = torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,requires_grad = True , dtype = torch.float))\n",
        "  #Forward method to define the computation in the model\n",
        "  def forward(self,x : torch.Tensor) -> torch.Tensor :\n",
        "    return self.weight * x + self.bias\n"
      ],
      "metadata": {
        "id": "UHJRA0X_ePfy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch model building esssentials :\n",
        "\n",
        "* torch.nn -> contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
        "\n",
        "* torch.nn.Parameter -> What parameters should our model try and learn , often a Pytorch layer from torch.nn will set these for us\n",
        "\n",
        "* torch.nn.Module -> The base class for all neural network modules , if you subclass it , you should overwrite forward()\n",
        "\n",
        "* torch.optim -> This where the optimizers in Pytorch live , they will help with gradient descent\n",
        "\n",
        "* def.forward() -> All nn.Module subclasses require you to overwrite forward() , this method defines what happens in the forward computation"
      ],
      "metadata": {
        "id": "hM42Sz6oLr6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking the contents of our Pytorch model\n",
        "\n",
        "* We can check our model's parameters or what's inside our model using .parameters()"
      ],
      "metadata": {
        "id": "TE2m4_q1QgRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a reproducable seed\n",
        "torch.manual_seed(42)\n",
        "#Creating a instance of the class\n",
        "model = LinearRegression()\n",
        "#Check out the parameters\n",
        "list(model.parameters())"
      ],
      "metadata": {
        "id": "Ors6T0iuQ391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdac799-356e-4236-a202-a958c46ceade"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #List the named parameters\n",
        " model.state_dict()"
      ],
      "metadata": {
        "id": "pc3NZj6eWfeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e26538-86ce-4a12-cc27-310b428969ca"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making prediction using 'torch.inference_mode()'\n",
        "\n",
        "To check our model's predictive power , let's check how well it predicts y_test based on x_test\n",
        "\n",
        "When we pass data through our model , it's going to run it through the forward() method"
      ],
      "metadata": {
        "id": "YZ8GWc8bYpHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions\n",
        "with torch.inference_mode():\n",
        "  y_pred = model(x_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BckF08SES01d",
        "outputId": "757f3a1e-4ff9-4ebc-a768-4240aff994b6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[27.7374],\n",
              "        [28.4108],\n",
              "        [29.0842],\n",
              "        [29.7576],\n",
              "        [30.4309],\n",
              "        [31.1043],\n",
              "        [31.7777],\n",
              "        [32.4511],\n",
              "        [33.1245],\n",
              "        [33.7978]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyIBaaFwZWDq",
        "outputId": "0df34ce5-4105-4201-a16c-1c9383d9cc0c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 82.],\n",
              "        [ 84.],\n",
              "        [ 86.],\n",
              "        [ 88.],\n",
              "        [ 90.],\n",
              "        [ 92.],\n",
              "        [ 94.],\n",
              "        [ 96.],\n",
              "        [ 98.],\n",
              "        [100.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model didn't perform well here because we had initialised random parameter"
      ],
      "metadata": {
        "id": "6Cw4wak0do-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model\n",
        "\n",
        "• Loss function: A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
        "\n",
        "\n",
        "• Optimizer: Takes into account the loss of a model and adjusts the model's parameters (e.g. weight & bias in our case) to improve the loss\n",
        "function.\n",
        "\n",
        "\n",
        "And specifically for PyTorch, we need:\n",
        "\n",
        "A training loop\n",
        "\n",
        "A testing loop"
      ],
      "metadata": {
        "id": "mUwmQX1ReRCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loss func\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "#optimizer func\n",
        "\n",
        "Optimizer = torch.optim.SGD(model.parameters() , lr = 0.0001)"
      ],
      "metadata": {
        "id": "F7N6jBpSZW7u"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rv95EmyYZY5V"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building a training loop and testing loop in Pytorch\n",
        "\n",
        "1.Loop through the data\n",
        "\n",
        "2.Forward pass (this involves data moving through our model's forward() functions) to make predictions on propagation\n",
        "\n",
        "3.Calculate the loss(compare forward pass predictions to ground truth labels)\n",
        "\n",
        "4.Optimizer zero grad\n",
        "\n",
        "5.Loss backward - moves backwards through the network to calculate the gradients of each of the parameters of the loss (backpropagation)\n",
        "\n",
        "6.Optimzer step - use the optimizer to adjust our model's parameters to try and improve the loss (gradient descent)"
      ],
      "metadata": {
        "id": "q1lv5Ph2ZaJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "from builtins import range\n",
        "#1.Loop through the data\n",
        "epochs = 1001\n",
        "for epoch in range(epochs):\n",
        "  #Set the model to training mode\n",
        "\n",
        "  model.train() #Train mode in Pytorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  #2.Forward pass\n",
        "\n",
        "  y_pred = model(x_train)\n",
        "\n",
        "  #3.Loss\n",
        "\n",
        "  Loss = loss_fn(y_pred , y_train)\n",
        "  #if(epoch % 10 == 0):\n",
        "    #print(f\"Loss is {Loss}\")\n",
        "\n",
        "  #4.Optimizer\n",
        "\n",
        "  Optimizer.zero_grad()\n",
        "\n",
        "  #5.Perform backpropagation on the loss with respect to the parameters of the model\n",
        "\n",
        "  Loss.backward()\n",
        "\n",
        "\n",
        "  #6.Step the optimzer(performs gradient descent)\n",
        "\n",
        "  Optimizer.step()\n",
        "\n",
        "  ##Testing\n",
        "  model.eval() #turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode():\n",
        "    #1.Forward pass\n",
        "\n",
        "    test_pred = model(x_test)\n",
        "\n",
        "    #2 Loss\n",
        "\n",
        "    test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "    if(epoch % 100 == 0):\n",
        "      print(f\"epoch : {epoch} , Loss : {Loss} , test_loss : {test_loss}\")\n",
        "      print(\"\\n\")\n",
        "      print(model.state_dict())\n",
        "\n",
        "#print(f\"Loss is {Loss}\")\n",
        "#print(f\" model.Parameter {model.state_dict()}\")"
      ],
      "metadata": {
        "id": "si6CUmBOo5H2",
        "outputId": "52df60ca-8723-403d-fa5d-a4223df0af95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0 , Loss : 27.066884994506836 , test_loss : 59.859169006347656\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.3408])), ('bias', tensor([0.1289]))])\n",
            "epoch : 100 , Loss : 10.246831893920898 , test_loss : 22.539051055908203\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.7508])), ('bias', tensor([0.1389]))])\n",
            "epoch : 200 , Loss : 0.06100674346089363 , test_loss : 0.02373199537396431\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9982])), ('bias', tensor([0.1435]))])\n",
            "epoch : 300 , Loss : 0.1251104176044464 , test_loss : 0.054277800023555756\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9979])), ('bias', tensor([0.1403]))])\n",
            "epoch : 400 , Loss : 0.058002687990665436 , test_loss : 0.01560211181640625\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9983])), ('bias', tensor([0.1372]))])\n",
            "epoch : 500 , Loss : 0.0707211047410965 , test_loss : 0.01400146447122097\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9987])), ('bias', tensor([0.1341]))])\n",
            "epoch : 600 , Loss : 0.0863601490855217 , test_loss : 0.34135133028030396\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9948])), ('bias', tensor([0.1310]))])\n",
            "epoch : 700 , Loss : 0.0822187140583992 , test_loss : 0.3470306396484375\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9948])), ('bias', tensor([0.1281]))])\n",
            "epoch : 800 , Loss : 0.08630158007144928 , test_loss : 0.334512323141098\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9949])), ('bias', tensor([0.1252]))])\n",
            "epoch : 900 , Loss : 0.08020086586475372 , test_loss : 0.34465789794921875\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9949])), ('bias', tensor([0.1225]))])\n",
            "epoch : 1000 , Loss : 0.06516014039516449 , test_loss : 0.3747085630893707\n",
            "\n",
            "\n",
            "OrderedDict([('weight', tensor([0.9946])), ('bias', tensor([0.1197]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Loss"
      ],
      "metadata": {
        "id": "hZoOmm_VxNus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff46b25-1101-45c3-c9e4-81d751b2fd8c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0652, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the Loss is below 1 which is great model"
      ],
      "metadata": {
        "id": "9rX_9Cng5K1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "id": "vCKC-aQuzek3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bbfa3f-f78d-43bd-8f27-cae2056d7012"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3747)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our training and testing model's loss is quite better"
      ],
      "metadata": {
        "id": "_GTT35Xx_YtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3BnJQdxdNRA",
        "outputId": "a8e592f1-2569-49f0-96d0-6200bf030d8e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.9946])), ('bias', tensor([0.1197]))])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving a model in Pytorch"
      ],
      "metadata": {
        "id": "BIUEbRMVfkOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 3 main methods you should about for saving and loading models in Pytorch\n",
        "\n",
        "1. \"torch.save()\" : Allows you save a Pytorch object in Python's pickle format\n",
        "\n",
        "2. \"torch.load()\" : allows you load a saved Pytorch object\n",
        "\n",
        "3. \"torch.nn.module.load_state_dict()\" : This allows to load a model's saved state dictionary"
      ],
      "metadata": {
        "id": "EnSqoQ53fpNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "id": "cdEtLpMZdP1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60582e4-093d-47ee-d5a3-428e9ed140aa"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.9946])), ('bias', tensor([0.1197]))])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving our Pytorch Model\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "#Create model directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents = True , exist_ok = True)\n",
        "\n",
        "#Create model save path\n",
        "MODEL_NAME = \"LinearRegression_pytorch.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "\n",
        "#Save the model state dict\n",
        "\n",
        "print(f\"Saving model to : {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj = model.state_dict() , f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_1J_uOPgbnB",
        "outputId": "a50e1f7c-3c27-4088-9f07-3bfefd86cf04"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to : models/LinearRegression_pytorch.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dwOPpc_pYzk"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading a model"
      ],
      "metadata": {
        "id": "WIADPushSwZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aince we saved our model's state_dict() rather the entire model , we'll create a new instance of our model class and state_dict() into that"
      ],
      "metadata": {
        "id": "jFVwxyORYuFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhLiE67dSzKe",
        "outputId": "05858afa-21e0-48a5-9e2e-ae2ca81b92cb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.9946])), ('bias', tensor([0.1197]))])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To load in a saved state_dict we have to instantiate a new instance of our model class\n",
        "\n",
        "loaded_model = LinearRegression()\n",
        "\n",
        "#Load the saved state dict of model (this will upate the new instance with updated parameter)\n",
        "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4iudozwY_8H",
        "outputId": "e5eef58a-be47-4037-f3b4-4648bdda6b47"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRtvSKkPZ0eS",
        "outputId": "582850b2-2677-49ee-b315-d611b275df12"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.9946])), ('bias', tensor([0.1197]))])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make some predictions with our loaded model\n",
        "loaded_model.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_pred = loaded_model(x_test)"
      ],
      "metadata": {
        "id": "1YuzN6DAZ_uh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  y_pred = model(x_test)"
      ],
      "metadata": {
        "id": "sJWQy-RUcBjq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking whether the loaded model and od model gives the same result"
      ],
      "metadata": {
        "id": "xftMS9OPdn3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred == loaded_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzJPxpBJcHkh",
        "outputId": "1d1e1c7d-ba68-4fd4-cee2-9d1b59fea51c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got true which means that our model is saved and loaded sucessfully"
      ],
      "metadata": {
        "id": "Bs1Q_nUyd0yp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKWupCH7cVgR"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}